# LLM Development POCs using Apple Silicon

## Why this repo is created?
As you may know I have been an engineering manager for Data Science Platform (Asgard) at Apple and spent a decade on Applied Science dealing with machine learning algorithms, evaluations, infrastructure and methods. Currently I am studying for my masters at Harvard on Data Science and in the course of which I discovered the joy of using my Apple Silicon Mac for machine learning.

Joy turned to practical horror as I had to go through multiple blog posts and piece together how to use libraries like MLX and Llama-CPP for developing Large Language Models (LLMs). In order to give something back to our community of machine learning enthusiasts, I decided to create this repo to host successfully executed POCs to demonstrate how wonderful Apple hardware can be to experiment and execute machine learning with.

I will start with LLAMA-CPP and MLX with as many practical examples that I can. Please feel free to leave an issue requests asking for libraries and example types that are not covered here.


## Structure

1. How to install llama-cpp with Apple Silicon Support  [llama-cpp-install](/llama-cpp-install/). 